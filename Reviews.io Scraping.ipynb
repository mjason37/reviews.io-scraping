{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IImport required modules\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from concurrent.futures import ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This functiion return all the cover page link(urls) from where we will scrape review information\n",
    "def generateCoverPage(url):\n",
    "    \"\"\"url = url of the company, we link to scrape reviews for\n",
    "    return = all the cover page links\"\"\"\n",
    "    \n",
    "    # To store cover page links\n",
    "    coverPage = []\n",
    "    r = requests.get(url)\n",
    "    s = BeautifulSoup(r.text, \"lxml\")\n",
    "    \n",
    "    # Extract total reviiews\n",
    "    totalReviews = s.findAll(\"span\", class_=\"TextBody TextBody--sm TextBody--inline\")[-1].find(\"strong\")\\\n",
    "    .text.replace(\"Reviews\", \"\").replace(\",\", \"\").strip()\n",
    "    \n",
    "    # Extract total page\n",
    "    totalPage = int(np.ceil(int(totalReviews)/20))\n",
    "    \n",
    "    # Create all the cover pages link\n",
    "    for pg in range(1, totalPage):\n",
    "        coverPage.append(f\"{url}/{pg}\")\n",
    "        \n",
    "    # Append the requested url at the start\n",
    "    coverPage = [url] + coverPage\n",
    "    return coverPage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function scrapes review, rating, reviewer, and review date\n",
    "def scrapeReviewInfo(url):\n",
    "    \"\"\"url = cover page urls\n",
    "    return = review info such as review, rating, reviewer, and review date as a dataframe\"\"\"\n",
    "    \n",
    "    # Initialize empty list of variables to be scraped\n",
    "    review = []\n",
    "    rating = []\n",
    "    reviewer = []\n",
    "    reviewDate = []\n",
    "    \n",
    "    \n",
    "    r = requests.get(url)\n",
    "    s = BeautifulSoup(r.text, \"lxml\")\n",
    "    \n",
    "    # This is the main container for each review\n",
    "    try:\n",
    "        mainCont = s.findAll(\"div\", class_=\"Review\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    # Extract review\n",
    "    try:\n",
    "        for cont in mainCont:\n",
    "            for cont1 in cont.findAll(class_=\"Review__body\"):\n",
    "                review.append(cont1.text.strip())\n",
    "    except:\n",
    "        review.append(\"na\")\n",
    "    \n",
    "    # Extract reviewer\n",
    "    try:\n",
    "        for cont in mainCont:\n",
    "            for cont1 in cont.findAll(class_=\"Review__author\"):\n",
    "                reviewer.append(cont1.text.strip())\n",
    "    except:\n",
    "        reviewer.append(\"na\")\n",
    "    \n",
    "    # Extract rating\n",
    "    try:\n",
    "        for cont in mainCont:\n",
    "            for cont1 in cont.findAll(\"div\", class_=\"Review__overallStars__stars\"):\n",
    "                rating.append(cont1.findAll(\"i\", class_=\"stars__icon icon-full-star-01\"))\n",
    "    except:\n",
    "        rating.append(\"na\")\n",
    "    \n",
    "    # Extract review data\n",
    "    try:\n",
    "        for cont in mainCont:\n",
    "            for cont1 in cont.findAll(class_=\"Review__dateSource\"):\n",
    "                reviewDate.append(cont1.text.strip())\n",
    "    except:\n",
    "        reviewDate.append(\"na\")\n",
    "    \n",
    "    # Create a df off scraped variables\n",
    "    df = pd.DataFrame({\n",
    "        \"review\":review,\n",
    "        \"reviewer\":reviewer,\n",
    "        \"rating\":rating,\n",
    "        \"reviewDate\":reviewDate\n",
    "    })\n",
    "    \n",
    "    # Extract rating in number from rating\n",
    "    df.rating = df.rating.str.len().astype(\"int\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap all the functions inside main\n",
    "def main(url):\n",
    "    coverPage = generateCoverPage(url)\n",
    "    with ProcessPoolExecutor(max_workers=4) as ex:\n",
    "        finalDf = pd.concat(list(ex.map(scrapeReviewInfo, coverPage))).reset_index(drop=True)\n",
    "    return finalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 203 ms, sys: 34.7 ms, total: 237 ms\n",
      "Wall time: 4.28 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(674, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Scrape one education review\n",
    "df = main(\"https://www.reviews.io/company-reviews/store/one-education\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“This was a fantastic course packed with amazi...</td>\n",
       "      <td>Gail Walton</td>\n",
       "      <td>4</td>\n",
       "      <td>Posted 16 hours ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“very helpful and easy to understand”</td>\n",
       "      <td>Fatimah</td>\n",
       "      <td>5</td>\n",
       "      <td>Posted 21 hours ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“Great content. Good instructions.”</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>4</td>\n",
       "      <td>Posted 1 day ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“Great course.”</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>5</td>\n",
       "      <td>Posted 1 day ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“Informative learning materials on this site, ...</td>\n",
       "      <td>Victoria Lewis</td>\n",
       "      <td>5</td>\n",
       "      <td>Posted 2 days ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>“How come i can’t get to do the exam?”</td>\n",
       "      <td>Gart Fletcher</td>\n",
       "      <td>2</td>\n",
       "      <td>Posted 2 days ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>“Found this on wowcher for a reduced price, th...</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>4</td>\n",
       "      <td>Posted 3 days ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>“Awesome!! Best course ever online, learning w...</td>\n",
       "      <td>Georgina Patterson</td>\n",
       "      <td>5</td>\n",
       "      <td>Posted 3 days ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>“I must tell you this course really help ne a ...</td>\n",
       "      <td>Itschok</td>\n",
       "      <td>5</td>\n",
       "      <td>Posted 3 days ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>“Gary - DSEAR - Excellent information clear, i...</td>\n",
       "      <td>Gary Broadhurst</td>\n",
       "      <td>5</td>\n",
       "      <td>Posted 4 days ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review            reviewer  \\\n",
       "0  “This was a fantastic course packed with amazi...         Gail Walton   \n",
       "1              “very helpful and easy to understand”             Fatimah   \n",
       "2                “Great content. Good instructions.”           Anonymous   \n",
       "3                                    “Great course.”           Anonymous   \n",
       "4  “Informative learning materials on this site, ...      Victoria Lewis   \n",
       "5             “How come i can’t get to do the exam?”       Gart Fletcher   \n",
       "6  “Found this on wowcher for a reduced price, th...           Anonymous   \n",
       "7  “Awesome!! Best course ever online, learning w...  Georgina Patterson   \n",
       "8  “I must tell you this course really help ne a ...             Itschok   \n",
       "9  “Gary - DSEAR - Excellent information clear, i...     Gary Broadhurst   \n",
       "\n",
       "   rating           reviewDate  \n",
       "0       4  Posted 16 hours ago  \n",
       "1       5  Posted 21 hours ago  \n",
       "2       4     Posted 1 day ago  \n",
       "3       5     Posted 1 day ago  \n",
       "4       5    Posted 2 days ago  \n",
       "5       2    Posted 2 days ago  \n",
       "6       4    Posted 3 days ago  \n",
       "7       5    Posted 3 days ago  \n",
       "8       5    Posted 3 days ago  \n",
       "9       5    Posted 4 days ago  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's preview the data\n",
    "df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
